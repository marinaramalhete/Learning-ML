{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizado Supervisionado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 - Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import neighbors\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "cmap_light = ListedColormap(['#FFFFAA', '#AAFFAA', '#AAAAFF','#EFEFEF'])\n",
    "cmap_bold  = ListedColormap(['#FFFF00', '#00FF00', '#0000FF','#000000'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - Funções para plotagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_regions_for_classifier_subplot(clf, X, y, X_test, y_test, title, subplot, target_names = None, plot_decision_regions = True):\n",
    "\n",
    "    numClasses = np.amax(y) + 1\n",
    "    color_list_light = ['#FFFFAA', '#EFEFEF', '#AAFFAA', '#AAAAFF']\n",
    "    color_list_bold = ['#EEEE00', '#000000', '#00CC00', '#0000CC']\n",
    "    cmap_light = ListedColormap(color_list_light[0:numClasses])\n",
    "    cmap_bold  = ListedColormap(color_list_bold[0:numClasses])\n",
    "\n",
    "    h = 0.03\n",
    "    k = 0.5\n",
    "    x_plot_adjust = 0.1\n",
    "    y_plot_adjust = 0.1\n",
    "    plot_symbol_size = 50\n",
    "\n",
    "    x_min = X[:, 0].min()\n",
    "    x_max = X[:, 0].max()\n",
    "    y_min = X[:, 1].min()\n",
    "    y_max = X[:, 1].max()\n",
    "    x2, y2 = np.meshgrid(np.arange(x_min-k, x_max+k, h), np.arange(y_min-k, y_max+k, h))\n",
    "\n",
    "    P = clf.predict(np.c_[x2.ravel(), y2.ravel()])\n",
    "    P = P.reshape(x2.shape)\n",
    "\n",
    "    if plot_decision_regions:\n",
    "        subplot.contourf(x2, y2, P, cmap=cmap_light, alpha = 0.8)\n",
    "\n",
    "    subplot.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold, s=plot_symbol_size, edgecolor = 'black')\n",
    "    subplot.set_xlim(x_min - x_plot_adjust, x_max + x_plot_adjust)\n",
    "    subplot.set_ylim(y_min - y_plot_adjust, y_max + y_plot_adjust)\n",
    "    \n",
    "    if (X_test is not None):\n",
    "        subplot.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cmap_bold, s=plot_symbol_size, marker='^', edgecolor = 'black')\n",
    "        train_score = clf.score(X, y)\n",
    "        test_score  = clf.score(X_test, y_test)\n",
    "        title = title + \"\\nTreinamento = {:.2f}, Teste = {:.2f}\".format(train_score, test_score)\n",
    "\n",
    "    subplot.set_title(title)\n",
    "\n",
    "    if (target_names is not None):\n",
    "        legend_handles = []\n",
    "        for i in range(0, len(target_names)):\n",
    "            patch = mpatches.Patch(color=color_list_bold[i], label=target_names[i])\n",
    "            legend_handles.append(patch)\n",
    "        subplot.legend(loc=0, handles=legend_handles)\n",
    "\n",
    "\n",
    "def plot_class_regions_for_classifier(clf, X, y, X_test=None, y_test=None, title=None, target_names = None, plot_decision_regions = True):\n",
    "\n",
    "    numClasses = np.amax(y) + 1\n",
    "    color_list_light = ['#FFFFAA', '#EFEFEF', '#AAFFAA', '#AAAAFF']\n",
    "    color_list_bold = ['#EEEE00', '#000000', '#00CC00', '#0000CC']\n",
    "    cmap_light = ListedColormap(color_list_light[0:numClasses])\n",
    "    cmap_bold  = ListedColormap(color_list_bold[0:numClasses])\n",
    "\n",
    "    h = 0.03\n",
    "    k = 0.5\n",
    "    x_plot_adjust = 0.1\n",
    "    y_plot_adjust = 0.1\n",
    "    plot_symbol_size = 50\n",
    "\n",
    "    x_min = X[:, 0].min()\n",
    "    x_max = X[:, 0].max()\n",
    "    y_min = X[:, 1].min()\n",
    "    y_max = X[:, 1].max()\n",
    "    x2, y2 = np.meshgrid(np.arange(x_min-k, x_max+k, h), np.arange(y_min-k, y_max+k, h))\n",
    "\n",
    "    P = clf.predict(np.c_[x2.ravel(), y2.ravel()])\n",
    "    P = P.reshape(x2.shape)\n",
    "    plt.figure()\n",
    "    if plot_decision_regions:\n",
    "        plt.contourf(x2, y2, P, cmap=cmap_light, alpha = 0.8)\n",
    "\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold, s=plot_symbol_size, edgecolor = 'black')\n",
    "    plt.xlim(x_min - x_plot_adjust, x_max + x_plot_adjust)\n",
    "    plt.ylim(y_min - y_plot_adjust, y_max + y_plot_adjust)\n",
    "\n",
    "    if (X_test is not None):\n",
    "        plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cmap_bold, s=plot_symbol_size, marker='^', edgecolor = 'black')\n",
    "        train_score = clf.score(X, y)\n",
    "        test_score  = clf.score(X_test, y_test)\n",
    "        title = title + \"\\nTrain score = {:.2f}, Test score = {:.2f}\".format(train_score, test_score)\n",
    "\n",
    "    if (target_names is not None):\n",
    "        legend_handles = []\n",
    "        for i in range(0, len(target_names)):\n",
    "            patch = mpatches.Patch(color=color_list_bold[i], label=target_names[i])\n",
    "            legend_handles.append(patch)\n",
    "        plt.legend(loc=0, handles=legend_handles)\n",
    "\n",
    "    if (title is not None):\n",
    "        plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - Exemplo de regressão logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "fruits = pd.read_table('./CSV/fruit_data_with_colors.txt')\n",
    "\n",
    "#fruits.head()\n",
    "\n",
    "X_fruits_2d = fruits[['height', 'width']]\n",
    "y_fruits_2d = fruits['fruit_label']\n",
    "\n",
    "fig, subaxes = plt.subplots(1, 1, figsize=(7, 5))\n",
    "y_fruits_apple = y_fruits_2d == 1   # apples vs todas as outras frutas\n",
    "\n",
    "X_train, X_test, y_train, y_test = (\n",
    "train_test_split(X_fruits_2d.as_matrix(),\n",
    "                y_fruits_apple.as_matrix(),\n",
    "                random_state = 0))\n",
    "\n",
    "clf = LogisticRegression(C=100).fit(X_train, y_train)\n",
    "\n",
    "plot_class_regions_for_classifier_subplot(clf, X_train, y_train, None,\n",
    "                                         None, 'Apple vs outras frutas',\n",
    "                                         subaxes)\n",
    "\n",
    "\n",
    "print(clf.predict([[6,8]]))\n",
    "\n",
    "\n",
    "print(clf.predict([[10,7]]))\n",
    "\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 - Criação de dados sintéticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "X_C2, y_C2 = make_classification(n_samples = 100, n_features=2,\n",
    "                                n_redundant=0, n_informative=2,\n",
    "                                n_clusters_per_class=1, flip_y = 0.2,\n",
    "                                class_sep = 0.5, random_state=0)\n",
    "\n",
    "plt.scatter(X_C2[:, 0], X_C2[:, 1], c=y_C2, marker='o', cmap=cmap_bold)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 - Regressão logística nos dados sintéticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_C2, y_C2,\n",
    "                                                   random_state = 0)\n",
    "\n",
    "fig, subaxes = plt.subplots(1, 1, figsize=(7, 5))\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "title = 'C = {:.3f}'.format(1.0)\n",
    "plot_class_regions_for_classifier_subplot(clf, X_train, y_train,\n",
    "                                         None, None, title, subaxes)\n",
    "\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 - Regressão logística e o parâmetro C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = (\n",
    "train_test_split(X_fruits_2d.as_matrix(),\n",
    "                y_fruits_apple.as_matrix(),\n",
    "                random_state=0))\n",
    "\n",
    "fig, subaxes = plt.subplots(3, 1, figsize=(4, 10))\n",
    "\n",
    "for this_C, subplot in zip([0.1, 1, 100], subaxes):\n",
    "    clf = LogisticRegression(C=this_C).fit(X_train, y_train)\n",
    "    title ='Apple vs. outras frutas, C = {:.3f}'.format(this_C)\n",
    "    \n",
    "    plot_class_regions_for_classifier_subplot(clf, X_train, y_train,\n",
    "                                             X_test, y_test, title,\n",
    "                                             subplot)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Máquinas de Vetores de Suporte\n",
    "#### (Support Vector Machines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6 - O exemplo linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_C2, y_C2, random_state = 0)\n",
    "\n",
    "fig, subaxes = plt.subplots(1, 1, figsize=(7, 5))\n",
    "this_C = 1.0\n",
    "clf = SVC(kernel = 'linear', C=this_C).fit(X_train, y_train)\n",
    "title = 'SVC linear, C = {:.3f}'.format(this_C)\n",
    "plot_class_regions_for_classifier_subplot(clf, X_train, y_train, None, None, title, subaxes)\n",
    "\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7 - SVM e o parâmetro C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_C2, y_C2, random_state = 0)\n",
    "fig, subaxes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "for this_C, subplot in zip([0.00001, 100], subaxes):\n",
    "    clf = LinearSVC(C=this_C).fit(X_train, y_train)\n",
    "    title = 'SVC linear, C = {:.5f}'.format(this_C)\n",
    "    print(clf.score(X_train, y_train))\n",
    "    print(clf.score(X_test, y_test))\n",
    "    print('\\n')\n",
    "    plot_class_regions_for_classifier_subplot(clf, X_train, y_train,\n",
    "                                             None, None, title, subplot)\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Máquinas de Vetores de Suportes - Kernelização\n",
    "#### (Kernelized Support Vector Machines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8 - Base de dados sintética com problema complexo de classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_D2, y_D2 = make_blobs(n_samples = 100, n_features = 2, centers = 8,\n",
    "                       cluster_std = 1.3, random_state = 4)\n",
    "y_D2 = y_D2 % 2\n",
    "plt.figure()\n",
    "plt.title('Problema complexo de classificação')\n",
    "plt.scatter(X_D2[:,0], X_D2[:,1], c=y_D2,\n",
    "           marker= 'o', s=50, cmap=cmap_bold)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9 - Kernel RBF vs. Polinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_D2, y_D2, random_state = 0)\n",
    "\n",
    "# Padrão é RBF\n",
    "plot_class_regions_for_classifier(SVC().fit(X_train, y_train),\n",
    "                                 X_train, y_train, None, None,\n",
    "                                 'Kernel RBF')\n",
    "\n",
    "# Kernel polinomial com grau = 3\n",
    "plot_class_regions_for_classifier(SVC(kernel = 'poly', degree = 3)\n",
    "                                 .fit(X_train, y_train), X_train,\n",
    "                                 y_train, None, None,\n",
    "                                 'Kernel polinomial, grau = 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10 - Kernel RBF e o parâmetro Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_D2, y_D2, random_state = 0)\n",
    "fig, subaxes = plt.subplots(3, 1, figsize=(4, 11))\n",
    "\n",
    "for this_gamma, subplot in zip([0.01, 1.0, 10.0], subaxes):\n",
    "    clf = SVC(kernel = 'rbf', gamma=this_gamma).fit(X_train, y_train)\n",
    "    title = 'Gamma = {:.2f}'.format(this_gamma)\n",
    "    plot_class_regions_for_classifier_subplot(clf, X_train, y_train,\n",
    "                                             None, None, title, subplot)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11 - Kernel RBF + parâmetros C e Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_D2, y_D2, random_state = 0)\n",
    "fig, subaxes = plt.subplots(3, 4, figsize=(15, 10), dpi=50)\n",
    "\n",
    "for this_gamma, this_axis in zip([0.01, 1, 5], subaxes):\n",
    "    \n",
    "    for this_C, subplot in zip([0.1, 1, 15, 250], this_axis):\n",
    "        title = 'gamma = {:.2f}, C = {:.2f}'.format(this_gamma, this_C)\n",
    "        clf = SVC(kernel = 'rbf', gamma = this_gamma,\n",
    "                 C = this_C).fit(X_train, y_train)\n",
    "        plot_class_regions_for_classifier_subplot(clf, X_train, y_train,\n",
    "                                                 X_test, y_test, title,\n",
    "                                                 subplot)\n",
    "        plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
